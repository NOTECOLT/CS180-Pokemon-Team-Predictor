{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgZjBst1-TO6"
      },
      "source": [
        "# Pokemon Team Predictor\n",
        "\n",
        "Authors:\n",
        "**Diego Eduardo A. Montenejo** (202005984)\n",
        "\n",
        "**Jayson Isaiah T. Tan** (202109224)\n",
        "\n",
        "This python notebook dives into the data preprocessing and model training stage of the project. You may also find the training and validation set accuracies of each of the three models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWe9wjCkwNqb"
      },
      "source": [
        "# JSON to DataFrame Conversion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bY50ni078adU",
        "outputId": "6f3b8dba-7474-429e-fc45-8e7282e55674"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/Shareddrives/CS180 ML Project/Implementation\n"
          ]
        }
      ],
      "source": [
        "#@title Mounting the Drive\n",
        "\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd \"/content/drive/Shareddrives/CS180 ML Project/Implementation/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQqXmGY1XU_S"
      },
      "outputs": [],
      "source": [
        "#@title Loading the Raw Dataset\n",
        "import pandas as pd\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "# Read Raw JSON data and convert to DataFrame\n",
        "# NOTE TO SELF: You can also import teams.json from the Google Drive into the runtime storage if mounting doesnt work\n",
        "file_path = 'teams.json'\n",
        "with open(file_path, 'r', encoding=\"utf8\") as file:\n",
        "    file_content = file.read()\n",
        "\n",
        "data = json.loads(file_content)\n",
        "df = pd.json_normalize(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbWxbD6qwUnu"
      },
      "source": [
        "# Dataset Cleaning & Feature Creation\n",
        "The following code preprocesses the data by doing the following:\n",
        "- Drop any irrelevant battle formats\n",
        "- Drop both the `format` and `replays` columns\n",
        "- Multiply the number of rows by 6, and select each pokemon from each team to be a \"focus\" (pokemon whose items, abilities, and moves will be predicted) under the column `pkmn`.\n",
        "- Concatenate all other non-focus pokemon team members into a single string under column `team`,\n",
        "  - Delete all non-focus pokemon team members' items moves abilities on each row.\n",
        "- For the focus pokemon team member, concatenate all four of its moves into a single string under column `moves`.\n",
        "- One-hot encode the `moves` and `team` columns.\n",
        "  - `team` is one-hot encoded on the output dataframe `x`.\n",
        "  - `moves` is one-hot encoded on the output dataframe `y`.\n",
        "\n",
        "The dataframe is exported to csv."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "oQ_lTN5jwFN_",
        "outputId": "785c25ef-41fd-4002-8047-a213bce127a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0       Drednaw Garchomp IronBundle ChienPao Kilowattrel \n",
            "1       Pelipper Garchomp IronBundle ChienPao Kilowatt...\n",
            "2       Pelipper Drednaw IronBundle ChienPao Kilowattrel \n",
            "3         Pelipper Drednaw Garchomp ChienPao Kilowattrel \n",
            "4       Pelipper Drednaw Garchomp IronBundle Kilowattrel \n",
            "                              ...                        \n",
            "7741    Glimmora IronValiant RoaringMoon SamurottHisui...\n",
            "7742    Glimmora IronMoth RoaringMoon SamurottHisui Gh...\n",
            "7743    Glimmora IronMoth IronValiant SamurottHisui Gh...\n",
            "7744    Glimmora IronMoth IronValiant RoaringMoon Ghol...\n",
            "7745    Glimmora IronMoth IronValiant RoaringMoon Samu...\n",
            "Name: team, Length: 7746, dtype: object\n"
          ]
        }
      ],
      "source": [
        "#@title Initial Preprocessing\n",
        "\n",
        "# Drop unncessary rows and columns\n",
        "df = df[(df['format'] == 'gen9Gen 9 OU Archive') | (df['format'] == 'gen9OverUsed')]\n",
        "df = df.drop(columns=['format', 'replays'])\n",
        "df = df.rename(columns={'pokemon': 'json'})\n",
        "\n",
        "def remove_spacedash(x):\n",
        "  return x.replace(' ', '').replace('-', '')\n",
        "# Create new Features\n",
        "for i in range(6):\n",
        "    df[f'pkmn{i+1}'] = df['json'].apply(lambda x: x[i]['name'])\n",
        "    for j in range(4):\n",
        "        df[f'pkmn{i+1}-move{j+1}'] = df['json'].apply(lambda x: x[i]['moves'][j] if j < len(x[i]['moves']) else 'None')\n",
        "    df[f'pkmn{i+1}-ability'] = df['json'].apply(lambda x: x[i]['ability'] if not (x[i].get('ability') is None) else 'None')\n",
        "    df[f'pkmn{i+1}-item'] = df['json'].apply(lambda x: x[i]['item'] if not (x[i].get('item') is None) else 'None')\n",
        "\n",
        "    # Remove all dashes and spaces from all names (to prevent issues with vectorizer)\n",
        "    df[f'pkmn{i+1}'] = df[f'pkmn{i+1}'].apply(remove_spacedash)\n",
        "    for j in range(4):\n",
        "      df[f'pkmn{i+1}-move{j+1}'] = df[f'pkmn{i+1}-move{j+1}'].apply(remove_spacedash)\n",
        "    df[f'pkmn{i+1}-ability'] = df[f'pkmn{i+1}-ability'].apply(remove_spacedash)\n",
        "    df[f'pkmn{i+1}-item'] = df[f'pkmn{i+1}-item'].apply(remove_spacedash)\n",
        "\n",
        "# Drop original JSON and indices\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "df = df.drop(columns=['json'])\n",
        "\n",
        "df.dropna(inplace=True)\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "# Now that we have separate all the information of each pokemon and all their abilities,\n",
        "#   we must separate each pokemon into their own data entry for prediction\n",
        "\n",
        "# Create a row for each pokemon in each team (effectively multiplying the number of rows by 6)\n",
        "df = df.loc[df.index.repeat(6)].reset_index(drop=True)\n",
        "\n",
        "# Copy the attributes of the focus pokemon to separate features\n",
        "df['pkmn'] = df.apply(lambda x: x[f'pkmn{(x.name % 6) + 1}'], axis=1)\n",
        "df['ability'] = df.apply(lambda x: x[f'pkmn{(x.name % 6) + 1}-ability'], axis=1)\n",
        "df['item'] = df.apply(lambda x: x[f'pkmn{(x.name % 6) + 1}-item'], axis=1)\n",
        "\n",
        "# We will use Bag of Words to aggregate all the team members and moves, thus we must gather them in a single string\n",
        "def get_teammates(x):\n",
        "    other_pkmn = ''\n",
        "    for i in range(6):\n",
        "      if i == x.name % 6:\n",
        "        continue\n",
        "      other_pkmn += x[f'pkmn{i+1}'] + ' '\n",
        "    return other_pkmn\n",
        "\n",
        "def get_moves(x):\n",
        "  moves = ''\n",
        "  for i in range(4):\n",
        "    moves += x[f'pkmn{(x.name % 6) + 1}-move{i+1}'] + ' '\n",
        "  return moves\n",
        "\n",
        "df['team'] = df.apply(get_teammates, axis=1)\n",
        "print(df['team'])\n",
        "df['moves'] = df.apply(get_moves, axis=1)\n",
        "\n",
        "# Drop all the previous features\n",
        "def pkmn_names(x):\n",
        "  return f'pkmn{x}'\n",
        "\n",
        "def pkmn_abilities(x):\n",
        "  return f'pkmn{x}-ability'\n",
        "\n",
        "def pkmn_items(x):\n",
        "  return f'pkmn{x}-item'\n",
        "\n",
        "old_features = [f(x+1) for x in range(6) for f in (pkmn_names, pkmn_abilities, pkmn_items)] + [f'pkmn{i+1}-move{j+1}' for j in range(4) for i in range(6)]\n",
        "df = df.drop(columns=old_features)\n",
        "\n",
        "# Drop invalid names, easier to do it at this stage rather than earlier\n",
        "df = df.drop(df[~df.pkmn.str.isalnum()].index)\n",
        "\n",
        "# Uncomment this if you want to see the full dataframe:\n",
        "df.to_csv('raw_dataset.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZoXvbjwViwxp",
        "outputId": "78fef5c4-347c-4f92-b03b-0e9d605403b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      focus_abomasnow  focus_alakazam  focus_alcremiesaltedcream  \\\n",
            "0                   0               0                          0   \n",
            "1                   0               0                          0   \n",
            "2                   0               0                          0   \n",
            "3                   0               0                          0   \n",
            "4                   0               0                          0   \n",
            "...               ...             ...                        ...   \n",
            "7741                0               0                          0   \n",
            "7742                0               0                          0   \n",
            "7743                0               0                          0   \n",
            "7744                0               0                          0   \n",
            "7745                0               0                          0   \n",
            "\n",
            "      focus_alomomola  focus_altaria  focus_altariamega  focus_amoonguss  \\\n",
            "0                   0              0                  0                0   \n",
            "1                   0              0                  0                0   \n",
            "2                   0              0                  0                0   \n",
            "3                   0              0                  0                0   \n",
            "4                   0              0                  0                0   \n",
            "...               ...            ...                ...              ...   \n",
            "7741                0              0                  0                0   \n",
            "7742                0              0                  0                0   \n",
            "7743                0              0                  0                0   \n",
            "7744                0              0                  0                0   \n",
            "7745                0              0                  0                0   \n",
            "\n",
            "      focus_ampharos  focus_annihilape  focus_appletun  ...  weavile  \\\n",
            "0                  0                 0               0  ...        0   \n",
            "1                  0                 0               0  ...        0   \n",
            "2                  0                 0               0  ...        0   \n",
            "3                  0                 0               0  ...        0   \n",
            "4                  0                 0               0  ...        0   \n",
            "...              ...               ...             ...  ...      ...   \n",
            "7741               0                 0               0  ...        0   \n",
            "7742               0                 0               0  ...        0   \n",
            "7743               0                 0               0  ...        0   \n",
            "7744               0                 0               0  ...        0   \n",
            "7745               0                 0               0  ...        0   \n",
            "\n",
            "      weezinggalar  wochien  zamazenta  zamazentacrowned  zapdos  zarude  \\\n",
            "0                0        0          0                 0       0       0   \n",
            "1                0        0          0                 0       0       0   \n",
            "2                0        0          0                 0       0       0   \n",
            "3                0        0          0                 0       0       0   \n",
            "4                0        0          0                 0       0       0   \n",
            "...            ...      ...        ...               ...     ...     ...   \n",
            "7741             0        0          0                 0       0       0   \n",
            "7742             0        0          0                 0       0       0   \n",
            "7743             0        0          0                 0       0       0   \n",
            "7744             0        0          0                 0       0       0   \n",
            "7745             0        0          0                 0       0       0   \n",
            "\n",
            "      zeraora  zoroark  zoroarkhisui  \n",
            "0           0        0             0  \n",
            "1           0        0             0  \n",
            "2           0        0             0  \n",
            "3           0        0             0  \n",
            "4           0        0             0  \n",
            "...       ...      ...           ...  \n",
            "7741        0        0             0  \n",
            "7742        0        0             0  \n",
            "7743        0        0             0  \n",
            "7744        0        0             0  \n",
            "7745        0        0             0  \n",
            "\n",
            "[7740 rows x 742 columns]\n"
          ]
        }
      ],
      "source": [
        "#@title One-Hot Encoding the Input\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# First, we Separate input x the original dataframe\n",
        "x = df.copy()[['pkmn', 'team']]\n",
        "\n",
        "# Renaming the contents of the pkmn column so that the focus pokemon is still discernable in the final model\n",
        "x['pkmn'] = \"focus_\" + x['pkmn']\n",
        "\n",
        "# Use a Count Vectorizer to vectorize the teams string and put them into separate\n",
        "x_vect = CountVectorizer()\n",
        "x_vect2 = CountVectorizer()\n",
        "x_doc_vec = x_vect.fit_transform(x['team'])\n",
        "x_doc_vec2 = x_vect2.fit_transform(x['pkmn'])\n",
        "\n",
        "\n",
        "team_vect = pd.DataFrame(x_doc_vec.toarray(), columns=x_vect.get_feature_names_out(), index=x.index)\n",
        "pkmn_vect = pd.DataFrame(x_doc_vec2.toarray(), columns=x_vect2.get_feature_names_out(), index=x.index)\n",
        "x = pd.concat([pkmn_vect, team_vect], axis=1)\n",
        "\n",
        "print(x)\n",
        "# Uncomment this if you want to see the full dataframe:\n",
        "x.to_csv('preprocessed_input.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80LDiCw45fFn",
        "outputId": "6f3b4d80-0b6e-4953-90c0-dd9878be6244"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             ability            item  \\\n",
            "0            Drizzle        DampRock   \n",
            "1          SwiftSwim       WhiteHerb   \n",
            "2          RoughSkin       FocusSash   \n",
            "3         QuarkDrive   BoosterEnergy   \n",
            "4        SwordofRuin  HeavyDutyBoots   \n",
            "...              ...             ...   \n",
            "7741      QuarkDrive   BoosterEnergy   \n",
            "7742      QuarkDrive   BoosterEnergy   \n",
            "7743  Protosynthesis   BoosterEnergy   \n",
            "7744       Sharpness  HeavyDutyBoots   \n",
            "7745      GoodasGold     CovertCloak   \n",
            "\n",
            "                                               moves  \n",
            "0                         Surf Roost Uturn KnockOff   \n",
            "1       ShellSmash Liquidation StoneEdge IceSpinner   \n",
            "2             StealthRock Spikes Earthquake Outrage   \n",
            "3                 HydroPump FreezeDry IceBeam Uturn   \n",
            "4        SwordsDance SacredSword IcicleCrash Crunch   \n",
            "...                                              ...  \n",
            "7741  FieryDance SludgeWave DazzlingGleam TeraBlast   \n",
            "7742   CloseCombat ShadowSneak KnockOff SwordsDance   \n",
            "7743     DragonDance Earthquake Acrobatics KnockOff   \n",
            "7744       Encore SacredSword CeaselessEdge AquaJet   \n",
            "7745     DazzlingGleam ShadowBall NastyPlot Recover   \n",
            "\n",
            "[7740 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "#@title Separating the Output\n",
        "\n",
        "# Separate the output y from the original dataframe\n",
        "y = df.copy()[['ability', 'item', 'moves']]\n",
        "\n",
        "# Uncomment this if you want to see the full dataframe:\n",
        "y.to_csv('preprocessed_output.csv', index=False)\n",
        "\n",
        "# Uncomment to check the abilities and items present:\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7DeyW5dm4sxu"
      },
      "outputs": [],
      "source": [
        "#@title Splitting the Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Create train test split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.7, test_size=0.3, random_state=33123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NusWFaTeiJ_u"
      },
      "outputs": [],
      "source": [
        "# @title Creating separate Ability, Item, Move Output Dataframes\n",
        "# 109 abilities listed\n",
        "# 181 items listed\n",
        "\n",
        "y_train_ability = y_train[\"ability\"]\n",
        "y_train_item = y_train[\"item\"]\n",
        "\n",
        "y_test_ability = y_test[\"ability\"]\n",
        "y_test_item = y_test[\"item\"]\n",
        "\n",
        "y_train_moves = y_train.drop(axis=1, labels=['ability', 'item'], inplace=False)\n",
        "y_test_moves = y_test.drop(axis=1, labels=['ability', 'item'], inplace=False)\n",
        "\n",
        "# creating a copy of x_test and x_train for testing with moves\n",
        "x_train_moves = x_train.copy()\n",
        "x_test_moves = x_test.copy()\n",
        "\n",
        "# Multiplying each row by 4 (for each move)\n",
        "x_train_moves = x_train_moves.loc[x_train_moves.index.repeat(4)].reset_index(drop=True)\n",
        "x_test_moves = x_test_moves.loc[x_test_moves.index.repeat(4)].reset_index(drop=True)\n",
        "\n",
        "y_train_moves = y_train_moves.loc[y_train_moves.index.repeat(4)].reset_index(drop=True)\n",
        "y_test_moves = y_test_moves.loc[y_test_moves.index.repeat(4)].reset_index(drop=True)\n",
        "\n",
        "# Function zeroes out all moves except for 1 in each row, depending on the index of the row\n",
        "y_train_moves = y_train_moves.apply(lambda x: x['moves'].split()[x.name % 4], axis=1)\n",
        "y_test_moves = y_test_moves.apply(lambda x: x['moves'].split()[x.name % 4], axis=1)\n",
        "\n",
        "# Uncomment me to see the full dataframe (warning: huge)\n",
        "y_train_moves.to_csv('y_train_moves.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3F9fCn4Jj-UW"
      },
      "outputs": [],
      "source": [
        "# Uncomment to see the shape of y_train_ability and x_train\n",
        "\n",
        "#print(y_train_ability.shape)\n",
        "#print(x_train.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OgRZfGX41St"
      },
      "source": [
        "# Training the Model\n",
        "For our Machine Learning Model, we use three separate Complement Naive Bayes models in order to predict the abilities, items, and moves of a pokemon given their team members. Based on the structure of our data, we found that Multinomial Naive Bayes was appropriate to use for the model, and on testing, Complement Naive Bayes performed better."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "CzzZr0Zz40zI",
        "outputId": "fd9c427e-e92f-46df-8f1a-d7ec98df0c9b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ComplementNB(class_prior=array([0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0...\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01]))"
            ],
            "text/html": [
              "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ComplementNB(class_prior=array([0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0...\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01]))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ComplementNB</label><div class=\"sk-toggleable__content\"><pre>ComplementNB(class_prior=array([0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0...\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01]))</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "#@title Fitting the Model to the Ability Dataset\n",
        "from sklearn.naive_bayes import ComplementNB\n",
        "\n",
        "# Ended up using ComplementNB since it's supposed to correct the \"assumptions\" Multinomial does.\n",
        "# Our input is like a DTM already so ComplementNB/MultinomialNB should be appropriate\n",
        "\n",
        "# A model is made just to get the amount of values needed to fill the matrix of prior probabilities\n",
        "ability_fakecnb = ComplementNB(alpha=1.0, force_alpha='warn', fit_prior=True)\n",
        "ability_fakecnb.fit(x_train, y_train_ability)\n",
        "\n",
        "ability_priors = np.full((ability_fakecnb.class_count_.shape[0],), 0.01)\n",
        "\n",
        "ability_cnb = ComplementNB(class_prior=ability_priors, alpha=1.0, force_alpha='warn', fit_prior=True)\n",
        "ability_cnb.fit(x_train, y_train_ability)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwucrPG1Ndii",
        "outputId": "3db4f1fa-f07c-4a5c-a549-57c9c6bdcb0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on training data\n",
            "0.9377999261720192\n",
            "Accuracy on test data\n",
            "0.9254952627045651\n"
          ]
        }
      ],
      "source": [
        "#@title Predicting the Ability of a Pokemon\n",
        "from sklearn import metrics\n",
        "\n",
        "# make class predictions for x_train using the predict() function\n",
        "y_train_ability_class = ability_cnb.predict(x_train)\n",
        "\n",
        "# make class predictions for x_test using the predict() function\n",
        "y_pred_ability_class = ability_cnb.predict(x_test)\n",
        "\n",
        "# calculate accuracy of class predictions\n",
        "print(\"Accuracy on training data\")\n",
        "print(metrics.accuracy_score(y_train_ability, y_train_ability_class))\n",
        "print(\"Accuracy on test data\")\n",
        "print(metrics.accuracy_score(y_test_ability, y_pred_ability_class))\n",
        "\n",
        "# Uncomment to check the probabilities for each class on the first sample in the training set:\n",
        "# ability_predictions = pd.DataFrame(ability_cnb.predict_proba(x_train)[0],index = ability_cnb.classes_).transpose()\n",
        "# ability_predictions.to_csv('ability_predictions.csv', index=False)\n",
        "# x_train.to_csv(\"x_train.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "qzR-EyCLllID",
        "outputId": "034e0ea7-bac3-49e1-81cd-b12d24b0d208"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ComplementNB(class_prior=array([0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01]))"
            ],
            "text/html": [
              "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ComplementNB(class_prior=array([0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01]))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ComplementNB</label><div class=\"sk-toggleable__content\"><pre>ComplementNB(class_prior=array([0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01]))</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "#@title Fitting the Model to the Held Item Dataset\n",
        "from sklearn.naive_bayes import ComplementNB\n",
        "\n",
        "# A model is made just to get the amount of values needed to fill the matrix of prior probabilities\n",
        "\n",
        "item_fakecnb = ComplementNB(alpha=1.0, force_alpha='warn', fit_prior=True)\n",
        "item_fakecnb.fit(x_train, y_train_item)\n",
        "\n",
        "item_priors = np.full((item_fakecnb.class_count_.shape[0],), 0.01)\n",
        "\n",
        "item_cnb = ComplementNB(class_prior=item_priors)\n",
        "item_cnb.fit(x_train, y_train_item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YY5Jj50HllIE",
        "outputId": "ebe6c0cc-0168-44c6-bc8a-b237f48e7721"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on training data\n",
            "0.6244001476559616\n",
            "Accuracy on test data\n",
            "0.5602928509905254\n"
          ]
        }
      ],
      "source": [
        "#@title Predicting the Held Item of a Pokemon\n",
        "from sklearn import metrics\n",
        "\n",
        "# make class predictions for x_train using the predict() function\n",
        "y_train_item_class = item_cnb.predict(x_train)\n",
        "\n",
        "# make class predictions for x_test using the predict() function\n",
        "y_pred_item_class = item_cnb.predict(x_test)\n",
        "\n",
        "# calculate accuracy of class predictions\n",
        "print(\"Accuracy on training data\")\n",
        "print(metrics.accuracy_score(y_train_item, y_train_item_class))\n",
        "print(\"Accuracy on test data\")\n",
        "print(metrics.accuracy_score(y_test_item, y_pred_item_class))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "QqYUrrb6uKFz",
        "outputId": "83b73517-9dba-4928-9346-9162646ed278"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ComplementNB(class_prior=array([0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0...\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01]))"
            ],
            "text/html": [
              "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ComplementNB(class_prior=array([0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0...\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01]))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ComplementNB</label><div class=\"sk-toggleable__content\"><pre>ComplementNB(class_prior=array([0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0...\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
              "       0.01, 0.01, 0.01]))</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "#@title Fitting the Model to the Moves Dataset\n",
        "from sklearn.naive_bayes import ComplementNB\n",
        "\n",
        "# WARNING: This takes like 4-5 minutes\n",
        "# A model is made just to get the amount of values needed to fill the matrix of prior probabilities\n",
        "moves_fakecnb = ComplementNB(alpha=1.0, force_alpha='warn', fit_prior=True)\n",
        "moves_fakecnb.fit(x_train_moves, y_train_moves)\n",
        "\n",
        "moves_priors = np.full((moves_fakecnb.class_count_.shape[0],), 0.01)\n",
        "\n",
        "moves_cnb = ComplementNB(class_prior=moves_priors)\n",
        "moves_cnb.fit(x_train_moves, y_train_moves)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbpeRnNSLze7",
        "outputId": "fbdd8be8-7b90-4634-b966-8f797aec49e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on training data:\n",
            "0.7332041343669251\n",
            "Accuracy on test data:\n",
            "0.6599913867355728\n"
          ]
        }
      ],
      "source": [
        "#@title Predicting the Moveset of a Pokemon\n",
        "\n",
        "\n",
        "# Uncomment to check the probabilities for each class on the first sample in the training set:\n",
        "#move_predictions = pd.DataFrame(moves_cnb.predict_proba(x_train_moves)[1],index = moves_cnb.classes_).transpose()\n",
        "#move_predictions.to_csv('moves_predictions.csv', index=False)\n",
        "#x_train_moves.to_csv(\"x_train_moves.csv\", index=False)\n",
        "#y_train_moves.to_csv(\"y_train_moves.csv\", index=False)\n",
        "\n",
        "\n",
        "# Due to the nature of the data and the predictions, the predict method of ComplementNB cannot be used since the top 4 moves should be predicted\n",
        "# and should not be done in a strict order\n",
        "# For this model, the accuracy is tested by checking if each move in the guessed moveset appears in the real moveset. If it does, increase the tally by 1\n",
        "# tally / {the total number of moves in the set} = accuracy of the model\n",
        "def move_accuracy_test(x_df, y_df):\n",
        "  move_predictions = pd.DataFrame(moves_cnb.predict_proba(x_df), columns=moves_cnb.classes_)\n",
        "  move_predictions.reset_index(inplace=True)\n",
        "\n",
        "  moves_true = []\n",
        "  for i in range(0, y_df.shape[0], 4):\n",
        "    moves_true.append(y_df[i:i+4].values)\n",
        "\n",
        "  moves_guesses = []\n",
        "  for index, row in move_predictions.iterrows():\n",
        "      if index % 4 == 0:\n",
        "        predicted_moves = row.sort_values(ascending=False).index\n",
        "        moves_guesses.append(predicted_moves[1:5])\n",
        "\n",
        "  tally = 0\n",
        "  for i in range(len(moves_guesses)):\n",
        "    for move in moves_guesses[i]:\n",
        "      if move in moves_true[i]:\n",
        "        tally += 1\n",
        "\n",
        "  score = tally / (len(moves_guesses) * 4)\n",
        "\n",
        "  return score\n",
        "\n",
        "print(\"Accuracy on training data:\")\n",
        "print(move_accuracy_test(x_train_moves, y_train_moves))\n",
        "print(\"Accuracy on test data:\")\n",
        "print(move_accuracy_test(x_test_moves, y_test_moves))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APnfiAOWXzFd"
      },
      "source": [
        "# Exporting the Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9CwTlJxXxKP"
      },
      "outputs": [],
      "source": [
        "#@title Export the Machine Learning Models\n",
        "\n",
        "import pickle\n",
        "\n",
        "# save the models to disk\n",
        "pickle.dump(ability_cnb, open('ability_cnb.sav', 'wb'))\n",
        "pickle.dump(item_cnb, open('item_cnb.sav', 'wb'))\n",
        "pickle.dump(moves_cnb, open('moves_cnb.sav', 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2usD004a2pH",
        "outputId": "efa83c11-1c1b-43b4-ced8-0aa62de58dbf",
        "cellView": "form"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Abomasnow' 'Alakazam' 'AlcremieSaltedCream' 'Alomomola' 'Altaria'\n",
            " 'AltariaMega' 'Amoonguss' 'Ampharos' 'Annihilape' 'Appletun' 'Araquanid'\n",
            " 'Arboliva' 'Arcanine' 'ArcanineHisui' 'Archaludon' 'Armarouge'\n",
            " 'ArticunoGalar' 'Avalugg' 'Azelf' 'Azumarill' 'Barraskewda' 'Basculegion'\n",
            " 'BasculegionF' 'Baxcalibur' 'Bellibolt' 'Bergmite' 'Bewear' 'Bisharp'\n",
            " 'Blaziken' 'Blissey' 'Brambleghast' 'Breloom' 'Bronzong' 'BruteBonnet'\n",
            " 'Cacturne' 'Carbink' 'Carvanha' 'Centiskorch' 'Ceruledge' 'Cetitan'\n",
            " 'Chandelure' 'Chansey' 'Charizard' 'CharizardMegaY' 'Chesnaught' 'ChiYu'\n",
            " 'ChienPao' 'Cinccino' 'Cinderace' 'Clefable' 'Clodsire' 'Cloyster'\n",
            " 'Cobalion' 'Comfey' 'Conkeldurr' 'Copperajah' 'Corviknight'\n",
            " 'Crabominable' 'Cramorant' 'Crawdaunt' 'Cresselia' 'Croagunk' 'Crocalor'\n",
            " 'Cryogonal' 'Cyclizar' 'Dachsbun' 'Darkrai' 'Darmanitan' 'DecidueyeHisui'\n",
            " 'Delibird' 'DeoxysDefense' 'DeoxysSpeed' 'Diancie' 'Dipplin' 'Ditto'\n",
            " 'Dolliv' 'Dondozo' 'Dragalge' 'Dragapult' 'Dragonair' 'Dragonite'\n",
            " 'Drednaw' 'Drifblim' 'Drifloon' 'Drowzee' 'Dudunsparce' 'Dugtrio'\n",
            " 'Dunsparce' 'Duraludon' 'Dusknoir' 'Eelektross' 'Electivire' 'Empoleon'\n",
            " 'Enamorus' 'EnamorusTherian' 'Espathra' 'Espeon' 'Excadrill'\n",
            " 'ExeggutorAlola' 'Farigiraf' 'Feraligatr' 'Ferrothorn' 'Fezandipiti'\n",
            " 'Flamigo' 'Floatzel' 'Florges' 'FlorgesWhite' 'FlutterMane' 'Flygon'\n",
            " 'Forretress' 'Fraxure' 'Froslass' 'Frosmoth' 'Gallade' 'Garchomp'\n",
            " 'Gardevoir' 'Garganacl' 'Gastrodon' 'GastrodonEast' 'Gengar' 'Gholdengo'\n",
            " 'Girafarig' 'Glaceon' 'Glastrier' 'Glimmet' 'Glimmora' 'Gliscor' 'Gogoat'\n",
            " 'Golduck' 'GolemAlola' 'Goodra' 'GoodraHisui' 'GougingFire'\n",
            " 'GourgeistSuper' 'Grafaiai' 'GreatTusk' 'Greninja' 'GreninjaBond'\n",
            " 'Grimmsnarl' 'Grookey' 'Gyarados' 'Hatterene' 'Hattrem' 'Hawlucha'\n",
            " 'Haxorus' 'Heatran' 'Heracross' 'Hippopotas' 'Hippowdon' 'Hitmontop'\n",
            " 'HoopaUnbound' 'Houndstone' 'Hydrapple' 'Hydreigon' 'Incineroar'\n",
            " 'Indeedee' 'IndeedeeF' 'Infernape' 'IronBoulder' 'IronBundle' 'IronCrown'\n",
            " 'IronHands' 'IronJugulis' 'IronLeaves' 'IronMoth' 'IronThorns'\n",
            " 'IronTreads' 'IronValiant' 'Jigglypuff' 'Jirachi' 'Keldeo' 'Kilowattrel'\n",
            " 'Kingambit' 'Kingdra' 'Kleavor' 'Klefki' 'Komala' 'Kommoo' 'Koraidon'\n",
            " 'Kyurem' 'LandorusTherian' 'Latias' 'LatiasMega' 'Latios' 'LatiosMega'\n",
            " 'Leafeon' 'Lechonk' 'Lilligant' 'LilligantHisui' 'Lokix' 'LopunnyMega'\n",
            " 'Lucario' 'Ludicolo' 'Luxray' 'Lycanroc' 'LycanrocDusk'\n",
            " 'LycanrocMidnight' 'Magearna' 'Magneton' 'Magnezone' 'Mamoswine'\n",
            " 'Manaphy' 'Mandibuzz' 'Mareanie' 'Masquerain' 'Maushold' 'MausholdFour'\n",
            " 'Medicham' 'Melmetal' 'Meowscarada' 'Metagross' 'Mew' 'Milotic' 'Mimikyu'\n",
            " 'Misdreavus' 'Mismagius' 'Moltres' 'MoltresGalar' 'Mudsdale' 'MukAlola'\n",
            " 'Munkidori' 'Naclstack' 'Natu' 'Necrozma' 'Ninetales' 'NinetalesAlola'\n",
            " 'Noivern' 'Numel' 'Ogerpon' 'OgerponCornerstone' 'OgerponHearthflame'\n",
            " 'OgerponWellspring' 'Okidogi' 'Oricorio' 'OricorioPomPom' 'OricorioSensu'\n",
            " 'Orthworm' 'Overqwil' 'Palafin' 'PalafinHero' 'Pawmot' 'Pawniard'\n",
            " 'Pecharunt' 'Pelipper' 'Pikachu' 'Pincurchin' 'Politoed' 'Poliwrath'\n",
            " 'Polteageist' 'PolteageistAntique' 'Primarina' 'Primeape' 'Pupitar'\n",
            " 'Quagsire' 'Quaquaval' 'Qwilfish' 'Rabsca' 'RagingBolt' 'Rapidash'\n",
            " 'Regieleki' 'Registeel' 'Reuniclus' 'Revavroom' 'Rhyperior' 'Ribombee'\n",
            " 'Rillaboom' 'RoaringMoon' 'Roserade' 'RotomFrost' 'RotomHeat' 'RotomWash'\n",
            " 'Sableye' 'SableyeMega' 'Salamence' 'Salazzle' 'SamurottHisui'\n",
            " 'Sandaconda' 'SandslashAlola' 'SandyShocks' 'SawsbuckWinter' 'Scizor'\n",
            " 'ScizorMega' 'Scovillain' 'ScreamTail' 'Seismitoad' 'Serperior' 'Seviper'\n",
            " 'ShayminSky' 'Shellder' 'ShellosEast' 'Shiftry' 'Sinistcha'\n",
            " 'SinistchaMasterpiece' 'Skarmory' 'Skeledirge' 'Slaking' 'Sliggoo'\n",
            " 'SlitherWing' 'Slowbro' 'SlowbroGalar' 'SlowbroMega' 'Slowking'\n",
            " 'SlowkingGalar' 'Smeargle' 'Smoliv' 'Sneasler' 'Spidops' 'Spiritomb'\n",
            " 'Squawkabilly' 'Staraptor' 'Starmie' 'Stunfisk' 'Sudowoodo' 'Suicune'\n",
            " 'Sunkern' 'Swalot' 'Sylveon' 'Talonflame' 'Tangrowth' 'TapuKoko'\n",
            " 'Tatsugiri' 'TatsugiriDroopy' 'TaurosPaldeaAqua' 'TaurosPaldeaBlaze'\n",
            " 'TaurosPaldeaFire' 'TaurosPaldeaWater' 'Tentacruel' 'Terapagos'\n",
            " 'TerapagosStellar' 'TerapagosTerastal' 'Thundurus' 'ThundurusTherian'\n",
            " 'TingLu' 'Tinkaton' 'Toedscool' 'Toedscruel' 'Togekiss' 'Torkoal'\n",
            " 'Tornadus' 'TornadusTherian' 'Torterra' 'Toxapex' 'Toxicroak'\n",
            " 'Toxtricity' 'ToxtricityLowKey' 'Tsareena' 'Tyranitar' 'Umbreon'\n",
            " 'Ursaluna' 'UrsalunaBloodmoon' 'Urshifu' 'UrshifuRapidStrike' 'Vaporeon'\n",
            " 'Veluza' 'Venusaur' 'Vespiquen' 'Victini' 'Volcanion' 'Volcarona'\n",
            " 'WalkingWake' 'Walrein' 'Weavile' 'WeezingGalar' 'WoChien' 'Zamazenta'\n",
            " 'ZamazentaCrowned' 'Zapdos' 'Zarude' 'Zeraora' 'Zoroark' 'ZoroarkHisui']\n"
          ]
        }
      ],
      "source": [
        "#@title Export the list of valid Pokemon names\n",
        "import csv\n",
        "\n",
        "valid_pkmn = df['pkmn'].unique()\n",
        "valid_pkmn.sort()\n",
        "print(valid_pkmn)\n",
        "\n",
        "with open('VALID_POKEMON.csv', 'w') as f:\n",
        "    write = csv.writer(f)\n",
        "    write.writerow(valid_pkmn)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}